{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source /data/Xilinx_no_Vitis/Vivado/2020.1/settings64.sh\n",
    "!vivado -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import hashlib\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from qkeras.qlayers import QDense\n",
    "from qkeras.quantizers import ternary\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "keras.utils.set_random_seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"./data\"\n",
    "test_data_dir = \"./data\"\n",
    "start_location = 100\n",
    "window_size = 400\n",
    "end_window = start_location + window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loadning training split\"\"\"\n",
    "x_train_path = os.path.join(train_data_dir, f'0528_X_train_0_770.npy')\n",
    "y_train_path = os.path.join(train_data_dir, f'0528_y_train_0_770.npy')\n",
    "\n",
    "assert os.path.exists(x_train_path), f\"ERROR: File {x_train_path} does not exist.\"\n",
    "assert os.path.exists(y_train_path), f\"ERROR: File {y_train_path} does not exist.\"\n",
    "\n",
    "X_train_val = np.load(x_train_path)\n",
    "y_train_val = np.load(y_train_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(X_train_val).hexdigest() == 'b61226c86b7dee0201a9158455e08ffb',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(y_train_val).hexdigest() == 'c59ce37dc7c73d2d546e7ea180fa8d31',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "# Get readout window\n",
    "X_train_val = X_train_val[:,start_location*2:end_window*2]\n",
    "assert len(X_train_val[0]) == (end_window-start_location)*2, f\"ERROR: X_test sample size {len(X_train_val[0])} does not match (start window, end window) ({start_location},{end_window}) size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading testing split\"\"\"\n",
    "x_test_path = os.path.join(test_data_dir, f'0528_X_test_0_770.npy')\n",
    "y_test_path = os.path.join(test_data_dir, f'0528_y_test_0_770.npy')\n",
    "\n",
    "assert os.path.exists(x_test_path), f\"ERROR: File {x_test_path} does not exist.\"\n",
    "assert os.path.exists(y_test_path), f\"ERROR: File {y_test_path} does not exist.\"\n",
    "\n",
    "X_test = np.load(x_test_path)\n",
    "y_test = np.load(y_test_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(X_test).hexdigest() == 'b7d85f42522a0a57e877422bc5947cde', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(y_test).hexdigest() == '8c9cce1821372380371ade5f0ccfd4a2', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "# Get readout window\n",
    "X_test = X_test[:,start_location*2:end_window*2]\n",
    "assert len(X_test[0]) == (end_window-start_location)*2, f\"ERROR: X_test sample size {len(X_test[0])} does not match (start window, end window) ({start_location},{end_window}) size.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our model \n",
    "QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models. We're using QDense layer instead of Dense. We're also training with model sparsity, since QKeras layers are prunable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = keras.models.Sequential()\n",
    "keras_model.add(QDense(\n",
    "    4, \n",
    "    activation=None, \n",
    "    name='fc1',\n",
    "    input_shape=(800,), \n",
    "    kernel_quantizer=ternary(),\n",
    "    bias_quantizer=ternary(),\n",
    "))\n",
    "keras_model.add(BatchNormalization(name='batchnorm1'))\n",
    "keras_model.add(QDense(\n",
    "    1, \n",
    "    name='fc2', \n",
    "    activation=None, \n",
    "    kernel_quantizer=ternary(),\n",
    "    bias_quantizer=ternary(),\n",
    "))\n",
    "\n",
    "print(keras_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_learning_rate = 1e-3\n",
    "validation_split = 0.05  # 45,000 sample size \n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "early_stopping_patience = 10\n",
    "\n",
    "checkpoint_dir = f'checkpoints/'\n",
    "checkpoint_filename = f'qkeras_model_best.h5'\n",
    "\n",
    "if os.path.exists(checkpoint_dir) == False:\n",
    "    print(f'Checkpoint directory {checkpoint_dir} does not exist.')\n",
    "    print('Creating directory...')\n",
    "    os.mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.load_weights(os.path.join(checkpoint_dir, checkpoint_filename))\n",
    "y_keras = keras_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, np.where(y_keras < 0, 0, 1).reshape(-1))\n",
    "\n",
    "print('\\n===================================')\n",
    "print(f'Start location = {start_location}, Window size = {window_size}')\n",
    "print('    Accuracy', test_acc)\n",
    "print('    Fidelity', test_acc*2-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to FPGA firmware "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an hls4ml config and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "# Create HLS configuration \n",
    "hls_config = {}\n",
    "hls_config['Model'] = {}\n",
    "hls_config = hls4ml.utils.config_from_keras_model(keras_model, granularity='name')\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'  # Default precision\n",
    "hls_config['Model']['ReuseFactor'] = 1  # parallelized \n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "keras_layers = ['fc1', 'fc1_alpha', 'fc1_linear', 'batchnorm1', 'fc2', 'fc2_alpha', 'fc2_linear']\n",
    "for layer in keras_layers:\n",
    "    hls_config['LayerName'][layer] = {}\n",
    "    hls_config['LayerName'][layer]['Precision'] = {}\n",
    "    if 'alpha' in layer: continue\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "# Input - ZCU216 uses 14-bit ADCS \n",
    "hls_config['LayerName']['fc1_input'] = {}\n",
    "hls_config['LayerName']['fc1_input']['Precision'] = {}\n",
    "hls_config['LayerName']['fc1_input']['Trace'] = False\n",
    "hls_config['LayerName']['fc1_input']['Precision'] = 'ap_fixed<14,14>' \n",
    "\n",
    "# Fc1\n",
    "hls_config['LayerName']['fc1']['Precision']['result'] = 'ap_fixed<20,20>'\n",
    "hls_config['LayerName']['fc1']['accum_t'] = 'ap_fixed<20,20>'\n",
    "\n",
    "# Fc1 activation \n",
    "hls_config['LayerName']['fc1_alpha']['Precision']['result'] = 'ap_fixed<20,20>'\n",
    "hls_config['LayerName']['fc1_linear']['Precision']['result'] = 'ap_fixed<20,20>'\n",
    "\n",
    "# Batchnormalization\n",
    "hls_config['LayerName']['batchnorm1']['Precision']['scale'] = 'ap_fixed<18,4>'\n",
    "hls_config['LayerName']['batchnorm1']['Precision']['bias'] = 'ap_fixed<18,4>'\n",
    "hls_config['LayerName']['batchnorm1']['Precision']['result'] = 'ap_fixed<10,4>'\n",
    "hls_config['LayerName']['batchnorm1']['accum_t'] = 'ap_fixed<10,4>'\n",
    "\n",
    "# Fc2\n",
    "hls_config['LayerName']['fc2']['Precision']['result'] = 'ap_fixed<21,21>'\n",
    "hls_config['LayerName']['fc2']['accum_t'] = 'ap_fixed<21,21>'\n",
    "\n",
    "# Fc2 activation \n",
    "hls_config['LayerName']['fc2_alpha']['Precision']['result'] = 'ap_fixed<21,21>'\n",
    "hls_config['LayerName']['fc2_linear']['Precision']['result'] = 'ap_fixed<21,21>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model=keras_model,\n",
    "    hls_config=hls_config,\n",
    "    output_dir='hls4ml_prj/',\n",
    "    part= 'xczu49dr-ffvf1760-2-e',\n",
    "    io_type='io_parallel',\n",
    "    clock_period=3.225,\n",
    "    backend='VivadoAccelerator',\n",
    "    board='zcu216',\n",
    "    interface='axi_stream',\n",
    "    project_name='NN'\n",
    ")\n",
    "\n",
    "# Visualize model\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()  # Must compile for C Sim. \n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare hls4ml and keras model\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test.astype(np.float32))) \n",
    "\n",
    "keras_acc = accuracy_score(y_test, np.where(y_keras <= 0, 0, 1).reshape(-1))\n",
    "hls_acc = accuracy_score(y_test, np.where(y_hls < 0, 0, 1).reshape(-1))\n",
    "\n",
    "print(f'Keras Acc: {keras_acc*100:.5}%')\n",
    "print(f'HLS Acc: {hls_acc*100:.5}:%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fidelity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground and excited indices \n",
    "e_indices = np.where(y_test == 1)[0]\n",
    "g_indices = np.where(y_test == 0)[0]\n",
    "\n",
    "# separate ground and excited samples \n",
    "Xe_test = X_test[e_indices]\n",
    "ye_test = y_test[e_indices]\n",
    "\n",
    "Xg_test = X_test[g_indices]\n",
    "yg_test = y_test[g_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute total correct for excited state \n",
    "ye_keras = keras_model.predict(Xe_test)\n",
    "ye_keras = np.where(ye_keras < 0, 0, 1).reshape(-1)\n",
    "e_accuracy = accuracy_score(ye_test, ye_keras)\n",
    "\n",
    "total_correct = (ye_test==ye_keras).astype(np.int8).sum()\n",
    "total_incorrect = (ye_test!=ye_keras).astype(np.int8).sum()\n",
    "\n",
    "# compute total correct for ground state \n",
    "yg_keras = keras_model.predict(Xg_test)\n",
    "yg_keras = np.where(yg_keras < 0, 0, 1)\n",
    "g_accuracy = accuracy_score(yg_test, yg_keras)\n",
    "\n",
    "total_correct = (yg_test==yg_keras).astype(np.int8).sum()\n",
    "total_incorrect = (yg_test!=yg_keras).astype(np.int8).sum()\n",
    "\n",
    "# compute fidelity \n",
    "keras_fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "keras_fidelity = keras_fidelity*2-1\n",
    "keras_fidelity = 1/2 + (0.5*keras_fidelity)\n",
    "\n",
    "\n",
    "# compute total correct for excited state \n",
    "ye_hls = hls_model.predict(Xe_test)\n",
    "ye_hls = np.where(ye_hls < 0, 0, 1).reshape(-1)\n",
    "e_accuracy = accuracy_score(ye_test, ye_hls)\n",
    "\n",
    "total_correct = (ye_test==ye_hls).astype(np.int8).sum()\n",
    "total_incorrect = (ye_test!=ye_hls).astype(np.int8).sum()\n",
    "\n",
    "# compute total correct for ground state \n",
    "yg_hls = hls_model.predict(Xg_test)\n",
    "yg_hls = np.where(yg_hls < 0, 0, 1)\n",
    "g_accuracy = accuracy_score(yg_test, yg_hls)\n",
    "\n",
    "total_correct = (yg_test==yg_hls).astype(np.int8).sum()\n",
    "total_incorrect = (yg_test!=yg_hls).astype(np.int8).sum()\n",
    "\n",
    "# compute fidelity \n",
    "hls_fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "hls_fidelity = hls_fidelity*2-1\n",
    "hls_fidelity = 1/2 + (0.5*hls_fidelity)\n",
    "\n",
    "\n",
    "print('\\n===================================')\n",
    "print('    Keras Fidelity', keras_fidelity)\n",
    "print('    HLS Fidelity', hls_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(\n",
    "    csim=False,\n",
    "    synth=True,\n",
    "    cosim=False,\n",
    "    export=False,\n",
    "    vsynth=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('hls4ml_prj/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4qick-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
